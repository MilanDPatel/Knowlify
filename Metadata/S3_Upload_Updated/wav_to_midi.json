{
    "topic": "is demonstrating the concept of creating a MIDI file from a list of notes,",
    "code": [
        "from manim_imports_ext import *\n",
        "\n",
        "import argparse\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import mido\n",
        "from collections import namedtuple\n",
        "from tqdm import tqdm as ProgressDisplay\n",
        "\n",
        "from scipy.signal import fftconvolve\n",
        "from scipy.signal import convolve\n",
        "from scipy.signal import argrelextrema\n",
        "from scipy.io import wavfile\n",
        "\n",
        "from IPython.terminal.embed import InteractiveShellEmbed\n",
        "embed = InteractiveShellEmbed()\n",
        "\n",
        "\n",
        "SAMPLED_VELOCITY = 100\n",
        "SAMPLED_VELOCITIES = list(range(25, 150, 25))\n",
        "DATA_DIR = os.path.join(\n",
        "    os.path.dirname(os.path.realpath(__file__)),\n",
        "    \"data\",\n",
        ")\n",
        "\n",
        "Note = namedtuple(\n",
        "    'Note',\n",
        "    [\n",
        "        'value',\n",
        "        'velocity',\n",
        "        'position',  # In seconds\n",
        "        'duration',  # In seconds\n",
        "    ]\n",
        ")\n",
        "\n",
        "major_scale = [0, 2, 4, 5, 7, 9, 11]\n",
        "piano_midi_range = list(range(21, 109))\n",
        "\n",
        "\n",
        "def square(vect):\n",
        "    return np.dot(vect, vect)\n",
        "\n",
        "\n",
        "def norm(vect):\n",
        "    return np.linalg.norm(vect)\n",
        "\n",
        "\n",
        "def projection_factor(v, w):\n",
        "    \"\"\"\n",
        "    If projecting v onto w produces the vector f * w, this returns f\n",
        "    \"\"\"\n",
        "    return np.dot(v, w) / np.dot(w, w)\n",
        "\n",
        "\n",
        "def gaussian_kernel(length=100, spread=0.5):\n",
        "    \"\"\"\n",
        "    creates gaussian kernel with side length `l` and a sigma of `sigma`\n",
        "    \"\"\"\n",
        "    sigma = spread * length\n",
        "    ax = np.linspace(-(length - 1) / 2., (length - 1) / 2., length)\n",
        "    gauss = np.exp(-0.5 * np.square(ax) / np.square(sigma))\n",
        "    return gauss / gauss.sum()\n",
        "\n",
        "\n",
        "# Functions for creating MIDI files\n",
        "\n",
        "\n",
        "def hz_to_midi_value(frequencies):\n",
        "    freqs = np.atleast_1d(frequencies)\n",
        "    return (12 * np.log2(freqs / 440) + 69).astype(int)\n",
        "\n",
        "\n",
        "def midi_value_to_hz(midis):\n",
        "    midis = np.atleast_1d(midis)\n",
        "    return 440 * 2**((midis - 69) / 12)\n",
        "\n",
        "\n",
        "def add_notes(track, notes, sec_per_tick):\n",
        "    \"\"\"\n",
        "    Adapted from https://github.com/aniawsz/rtmonoaudio2midi\n",
        "    \"\"\"\n",
        "    curr_tick = 0\n",
        "    for index, note in enumerate(notes):\n",
        "        pos_in_ticks = int(note.position / sec_per_tick)\n",
        "        dur_in_ticks = int(note.duration / sec_per_tick)\n",
        "\n",
        "        if index < len(notes) - 1:\n",
        "            next_pos_in_ticks = int(notes[index + 1].position / sec_per_tick)\n",
        "            dur_in_ticks = min(dur_in_ticks, next_pos_in_ticks - pos_in_ticks)\n",
        "\n",
        "        track.append(\n",
        "            mido.Message(\n",
        "                'note_on',\n",
        "                note=int(note.value),\n",
        "                velocity=int(note.velocity),\n",
        "                time=pos_in_ticks - curr_tick\n",
        "            )\n",
        "        )\n",
        "        curr_tick = pos_in_ticks\n",
        "        track.append(\n",
        "            mido.Message(\n",
        "                'note_off',\n",
        "                note=int(note.value),\n",
        "                # velocity=int(note.velocity),\n",
        "                time=dur_in_ticks,\n",
        "            )\n",
        "        )\n",
        "        curr_tick = pos_in_ticks + dur_in_ticks\n",
        "\n",
        "\n",
        "def create_midi_file_with_notes(filename, notes, bpm=240):\n",
        "    \"\"\"\n",
        "    From https://github.com/aniawsz/rtmonoaudio2midi\n",
        "    \"\"\"\n",
        "    with mido.MidiFile() as midifile:\n",
        "        # Tempo is microseconds per beat\n",
        "        sec_per_tick = (60.0 / bpm) / midifile.ticks_per_beat\n",
        "\n",
        "        # Create one track for each piano key\n",
        "        tracks = []\n",
        "        for key in piano_midi_range:\n",
        "            track = mido.midifiles.MidiTrack()\n",
        "            matching_notes = list(filter(lambda n: n.value == key, notes))\n",
        "            matching_notes.sort(key=lambda n: n.position)\n",
        "            if len(matching_notes) == 0:\n",
        "                continue\n",
        "            add_notes(track, matching_notes, sec_per_tick)\n",
        "            tracks.append(track)\n",
        "\n",
        "        master_track = mido.midifiles.MidiTrack()\n",
        "        # master_track.append(mido.MetaMessage('instrument_name', name='Steinway Grand Piano', time=0))\n",
        "        master_track.append(mido.MetaMessage('instrument_name', name='Learner\\'s Piano', time=0))\n",
        "        master_track.append(mido.MetaMessage('set_tempo', tempo=tempo))\n",
        "        master_track.extend(mido.merge_tracks(tracks))\n",
        "        midifile.tracks.append(master_track)\n",
        "\n",
        "        midifile.save(filename)\n",
        "\n",
        "\n",
        "def midi_to_wav(mid_file):\n",
        "    wav_file = mid_file.replace(\".mid\", \".wav\")\n",
        "    mp3_file = mid_file.replace(\".mid\", \".mp3\")\n",
        "    if os.path.exists(wav_file):\n",
        "        os.remove(wav_file)\n",
        "    os.system(\" \".join([\n",
        "        \"timidity\",\n",
        "        mid_file,\n",
        "        \"-Ow -o -\",\n",
        "        \"|\",\n",
        "        \"ffmpeg\",\n",
        "        \"-i - -acodec libmp3lame -ab 64k\",\n",
        "        \"-ar 48000\",\n",
        "        \"-hide_banner -loglevel error\",\n",
        "        mp3_file,\n",
        "    ]))\n",
        "    os.system(\" \".join([\n",
        "        \"ffmpeg\",\n",
        "        \"-hide_banner -loglevel error\",\n",
        "        \"-i\",\n",
        "        mp3_file,\n",
        "        wav_file,\n",
        "    ]))\n",
        "    os.remove(mp3_file)\n",
        "    return wav_file\n",
        "\n",
        "\n",
        "def generate_pure_piano_key_files(velocities=[SAMPLED_VELOCITY], duration=0.025, folder=\"digital_piano_samples\"):\n",
        "    folder = os.path.join(DATA_DIR, folder)\n",
        "    if not os.path.exists(folder):\n",
        "        os.makedirs(folder)\n",
        "\n",
        "    for key in piano_midi_range:\n",
        "        for vel in velocities:\n",
        "            note = Note(key, vel, 0, duration)\n",
        "            mid_file = os.path.join(folder, f\"{key}_{vel}.mid\")\n",
        "            create_midi_file_with_notes(mid_file, [note])\n",
        "            midi_to_wav(mid_file)\n",
        "            os.remove(mid_file)\n",
        "\n",
        "\n",
        "def generate_piano_sample_midi(delay=5, duration=0.025, velocity=100):\n",
        "    notes = []\n",
        "    for n, key in enumerate(piano_midi_range):\n",
        "        notes.append(Note(\n",
        "            key,\n",
        "            velocity=velocity,\n",
        "            position=n * delay,\n",
        "            duration=duration,\n",
        "        ))\n",
        "    mid_file = os.path.join(DATA_DIR, \"individual_key_samples.mid\")\n",
        "    create_midi_file_with_notes(mid_file, notes)\n",
        "    midi_to_wav(mid_file)\n",
        "\n",
        "\n",
        "# Processing sample signals from piano\n",
        "\n",
        "def load_piano_key_signals(folder=\"piano_samples\", duration=0.5, velocity=50):\n",
        "    key_signals = []\n",
        "    for key in piano_midi_range:\n",
        "        sample_rate, full_signal = wav_data(\n",
        "            os.path.join(DATA_DIR, folder, f\"{key}_{velocity}.wav\")\n",
        "        )\n",
        "        key_signal = full_signal[:int(duration * sample_rate)]\n",
        "        key_signals.append(key_signal)\n",
        "    return np.array(key_signals, dtype=float)\n",
        "\n",
        "\n",
        "def get_volume_to_velocity_func_map(folder=\"true_piano_samples\", sampled_velocities=[26, 101]):\n",
        "    \"\"\"\n",
        "    Functions are encoded as a pair (c0, c1) for the linear function c0 + c1 * x\n",
        "    \"\"\"\n",
        "    result = dict()\n",
        "    vels = sampled_velocities\n",
        "    for key in piano_midi_range:\n",
        "        volumes = [\n",
        "            wav_data(os.path.join(DATA_DIR, folder, f\"{key}_{vel}.wav\"))[1].max()\n",
        "            for vel in vels\n",
        "        ]\n",
        "        # Coefficients for const + (slope) * x function fit\n",
        "        slope = (vels[1] - vels[0]) / (volumes[1] - volumes[0])\n",
        "        const = vels[0] - slope * volumes[0]\n",
        "        result[key] = (const, slope)\n",
        "    return result\n",
        "\n",
        "\n",
        "def get_velocity(key, signal, scale_factor, v2v_func_map):\n",
        "    c0, c1 = v2v_func_map[key]\n",
        "    return c0 + c1 * (signal.max() * scale_factor)\n",
        "\n",
        "\n",
        "def shift_pitch(signal, sample_rate, shift_in_hz, frame_size=4800):\n",
        "    result = []\n",
        "    for lh in range(0, len(signal), frame_size):\n",
        "        rh = lh + frame_size\n",
        "        fft_spectrum = np.fft.rfft(signal[lh:rh])\n",
        "        freq = sample_rate / (rh - lh)\n",
        "        shift = int(shift_in_hz / freq)\n",
        "        shifted_spectrum = np.zeros_like(fft_spectrum)\n",
        "        shifted_spectrum[shift:] = fft_spectrum[:-shift]\n",
        "        shifted_signal = np.fft.irfft(shifted_spectrum)\n",
        "        result.append(shifted_signal)\n",
        "    return np.hstack(result)\n",
        "\n",
        "\n",
        "def wav_to_midi(sound_file,\n",
        "                output_file=None,\n",
        "                key_block_time=0.075,\n",
        "                key_signal_time=0.075,\n",
        "                key_play_time=0.020,\n",
        "                step_size=0.001,\n",
        "                sample_velocity=100,\n",
        "                sample_folder=\"digital_piano_samples\",\n",
        "                key_signal_max=0.15,  # This has a very large effect\n",
        "                volume_ratio_threshold=1.0,\n",
        "                scale_factor_cutoff=0.1,\n",
        "                min_velocity=5,\n",
        "                max_velocity=60,\n",
        "                # Honestly, low keys are trash, so many are supressed\n",
        "                n_supressed_lower_keys=32,\n",
        "                supression_factor=0.25,\n",
        "                ):\n",
        "    \"\"\"\n",
        "    Walk through a series of windows over the original signal, and for each one,\n",
        "    find the top several key sounds which correlate most closely with that window.\n",
        "    More specifically, do a convolution to let that piano key signal 'slide' along\n",
        "    the window to find the best possible match.\n",
        "\n",
        "    Room for improvement:\n",
        "        - Duration shouldn't necessarily be fixed\n",
        "    \"\"\"\n",
        "    # Read in audio file, normalize\n",
        "    sample_rate, signal = wav_data(sound_file)\n",
        "    signal /= signal.max()\n",
        "    new_signal = np.zeros_like(signal)\n",
        "\n",
        "    # We (potentially) add one note per step_size. A single note cannot be played\n",
        "    # multiple times within a key_block_size window.\n",
        "    step_size = int(sample_rate * step_size)\n",
        "    key_block_size = int(sample_rate * key_block_time)\n",
        "\n",
        "    notes = []\n",
        "    key_signals = load_piano_key_signals(\n",
        "        folder=sample_folder,\n",
        "        duration=key_signal_time,\n",
        "        velocity=sample_velocity,\n",
        "    )\n",
        "    key_signals *= key_signal_max / key_signals.max()\n",
        "\n",
        "    velocities = []  # Just for debugging, can delete\n",
        "\n",
        "    # Compute correlations between all notes at all points along the signal\n",
        "    full_convs = np.array([\n",
        "        fftconvolve(signal, ks[::-1])[len(ks) - 1:]\n",
        "        for ks in key_signals\n",
        "    ])\n",
        "    # Repress lower keys.  TODO: Instead of multiplying by an arbitrary factor, use some smoothing function\n",
        "    full_convs[:n_supressed_lower_keys, :] *= supression_factor\n",
        "\n",
        "    # The signal is divided into many little windows, with these \"positions\" marking\n",
        "    # the first index of each such window. These are sorted based on which ones\n",
        "    # have the highest correlation with some particular key.\n",
        "    positions = list(range(0, len(signal), step_size))\n",
        "    positions.sort(key=lambda p: -full_convs[:, p:p + step_size].max())\n",
        "    for pos in positions:\n",
        "        window = signal[pos:pos + step_size]\n",
        "        new_window = new_signal[pos:pos + step_size]\n",
        "\n",
        "        # When volume is larger than original window, stop adding new notes\n",
        "        if norm(new_window) > volume_ratio_threshold * norm(window):\n",
        "            continue\n",
        "\n",
        "        convs = full_convs[:, pos:pos + step_size]\n",
        "        key_index, offset = np.unravel_index(np.argmax(convs), convs.shape)\n",
        "        opt_pos = pos + offset\n",
        "        ks = key_signals[key_index]\n",
        "\n",
        "        # Consider the segment of the original signal which lines up\n",
        "        # with this key signal as a vector. If you project that segment\n",
        "        # onto the key signal itself, producing a vector which is f * (key signal),\n",
        "        # this factor gives f.\n",
        "        diff = (signal - new_signal)[opt_pos:opt_pos + len(ks)]  # What's the right length here?\n",
        "        factor = projection_factor(diff, ks[:len(diff)])\n",
        "\n",
        "        if factor > scale_factor_cutoff:\n",
        "            velocity = int(interpolate(min_velocity, max_velocity, clip(factor, 0, 1)))\n",
        "            velocities.append((factor, velocity))\n",
        "            # Add the key_signal to new_window, which will in turn be added to new_signal\n",
        "            piece = new_signal[opt_pos:opt_pos + len(ks)]\n",
        "            piece += (velocity / sample_velocity) * ks[:len(piece)]\n",
        "            # Mark this key as unavailable for the next len(ks) samples\n",
        "            full_convs[key_index, opt_pos:opt_pos + key_block_size] = 0\n",
        "            # Add the note, which will ultimately be used to create the MIDI file\n",
        "            notes.append(Note(\n",
        "                value=piano_midi_range[key_index],\n",
        "                velocity=velocity,\n",
        "                position=opt_pos / sample_rate,\n",
        "                # Always hit with a short staccato\n",
        "                duration=key_play_time,\n",
        "            ))\n",
        "\n",
        "    if output_file is None:\n",
        "        output_file = sound_file.replace(\".wav\", \"_as_piano.mid\")\n",
        "    create_midi_file_with_notes(output_file, notes)\n",
        "    midi_to_wav(output_file)\n",
        "\n",
        "    # plt.plot(signal, linewidth=1.0)\n",
        "    # plt.plot(new_signal, linewidth=1.0)\n",
        "    # plt.plot(smooth_signal, linewidth=1.0)\n",
        "    # plt.show()\n",
        "    return\n",
        "\n",
        "\n",
        "# Functions for processing sound files\n",
        "\n",
        "\n",
        "def show_down_midi_file(mid_file, slow_factor=4):\n",
        "    mid = mido.MidiFile(mid_file, clip=True)\n",
        "    track = mid.tracks[0]\n",
        "\n",
        "    for msg in track:\n",
        "        if msg.type in ['note_on', 'note_off']:\n",
        "            msg.time *= slow_factor\n",
        "    new_file = mid_file.replace(\".mid\", f\"_slowed_by_{slow_factor}.mid\")\n",
        "    mid.save(new_file)\n",
        "    return new_file\n",
        "\n",
        "\n",
        "def wav_data(file_name):\n",
        "    rate, arr = wavfile.read(file_name)\n",
        "    arr = arr.astype(float)\n",
        "    if len(arr.shape) > 1 and arr.shape[1] > 1:\n",
        "        arr = arr.mean(1)  # Collapse to single channel\n",
        "    return rate, arr\n",
        "\n",
        "\n",
        "def extract_pure_keys(key_sample_file,\n",
        "                      output_folder=\"true_piano_samples\",\n",
        "                      start=3.9,\n",
        "                      spacing=3,\n",
        "                      velocities=[1, 26, 51, 76, 101, 126]):\n",
        "    \"\"\"\n",
        "    For a file\n",
        "    \"\"\"\n",
        "    output_folder = os.path.join(DATA_DIR, output_folder)\n",
        "    sample_rate, arr = wav_data(key_sample_file)\n",
        "\n",
        "    # Create function whose local maxima correspond to key starts\n",
        "    kernel = np.ones(sample_rate) / sample_rate\n",
        "    smoothed = fftconvolve(np.abs(arr).astype(float), kernel, mode='valid')\n",
        "    smoothed = fftconvolve(smoothed, kernel, mode='valid')\n",
        "    smooth_to_true_shift = int(0.7 * sample_rate)\n",
        "    smoothed = np.hstack([np.zeros(smooth_to_true_shift), smoothed])\n",
        "    local_maxima = argrelextrema(smoothed, np.greater)[0]\n",
        "\n",
        "    def true_peak_near(index):\n",
        "        return local_maxima[np.argmin(np.abs(local_maxima - index))]\n",
        "\n",
        "    spacing_in_samples = int(spacing * sample_rate)\n",
        "    index = true_peak_near(start * sample_rate)\n",
        "    for key in piano_midi_range:\n",
        "        for vel in velocities:\n",
        "            wavfile.write(\n",
        "                filename=os.path.join(output_folder, f\"{key}_{vel}.wav\"),\n",
        "                rate=sample_rate,\n",
        "                data=arr[index:index + spacing_in_samples],\n",
        "            )\n",
        "            index = true_peak_near(index + spacing_in_samples)\n",
        "    return\n",
        "\n",
        "\n",
        "def normalize_data(data):\n",
        "    return data / np.abs(data).max()\n",
        "\n",
        "\n",
        "def data_to_audio_segment(segment):\n",
        "    pass\n",
        "\n",
        "\n",
        "def test_midi_file_writing():\n",
        "    notes = [\n",
        "        Note(\n",
        "            value=hz_to_midi_value(240 * 2**((5 * x % 12) / 12)),\n",
        "            velocity=random.randint(20, 64),\n",
        "            position=x / 120,\n",
        "            duration=1 / 120,\n",
        "        )\n",
        "        for x in range(64)\n",
        "        for y in range(10)\n",
        "    ]\n",
        "    test_file = os.path.join(DATA_DIR, \"test.mid\")\n",
        "    create_midi_file_with_notes(\n",
        "        test_file, notes\n",
        "    )\n",
        "\n",
        "    mid = mido.MidiFile(test_file, clip=True)\n",
        "    track = mid.tracks[0]\n",
        "    print(track)\n",
        "\n",
        "\n",
        "def plot_velocity_data():\n",
        "    key = 55\n",
        "    folder = os.path.join(DATA_DIR, \"true_piano_samples\")\n",
        "    signals = []\n",
        "    vels = list(range(1, 127, 25))\n",
        "    for vel in vels:\n",
        "        file = os.path.join(folder, f\"{key}_{vel}.wav\")\n",
        "        rate, signal = wav_data(file)\n",
        "        signals.append(signal)\n",
        "\n",
        "    maxes = [s.max() for s in signals]\n",
        "    plt.plot(maxes, vels)\n",
        "    plt.plot(np.linspace(0, maxes[-1], len(maxes)), vels)\n",
        "    plt.show()\n",
        "\n",
        "    embed()\n",
        "\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"wav_file\")\n",
        "    parser.add_argument(\"output_file\", nargs=\"?\")\n",
        "    args = parser.parse_args()\n",
        "    wav_to_midi(args.wav_file, args.output_file)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "\n",
        "    # mid1 = mido.MidiFile(\"/Users/grant/cs/videos/_2022/piano/data/better_midis/TrappedInAPiano.wav.mid\")\n",
        "    # mid2 = mido.MidiFile(\"/Users/grant/cs/videos/_2022/piano/data/3-9-attempts/DensityTest_5ms.mid\")\n",
        "    # track1 = mid1.tracks[0]\n",
        "    # track2 = mid2.tracks[0]"
    ]
}